{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Fyl4InUs07"
      },
      "source": [
        "## Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gt2nLObm6W8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install huggingface_hub datasets\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install nltk\n",
        "!pip install chromadb\n",
        "!pip install unstructured\n",
        "!pip install pdf2image\n",
        "!pip install pdfminer\n",
        "!pip install llmsherpa\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlAx89UHTIiH"
      },
      "source": [
        "## Carregas dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdc_AbvtTLaO"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://www.pg.unicamp.br/norma/31594/0\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dyhB4YA1yVb"
      },
      "source": [
        "## split RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2PEdJSRJyCm"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=32)\n",
        "texts_RecursiveCharacterTextSplitter = text_splitter.split_documents(docs)\n",
        "\n",
        "simple_splited_texts = [x.page_content for x in texts_RecursiveCharacterTextSplitter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Or2lQjTGz_"
      },
      "source": [
        "## Split nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkqoeMWdX_2J"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3JvvpCPDLhk"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "\n",
        "text_splitter = NLTKTextSplitter(language = \"portuguese\", chunk_size=512, chunk_overlap  = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDCrQc9NVXyM"
      },
      "outputs": [],
      "source": [
        "texts_NLTKTextSplitter = text_splitter.split_documents(docs)\n",
        "\n",
        "nltk_splited_texts = [x.page_content for x in texts_NLTKTextSplitter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIqUMMVz1t0c"
      },
      "source": [
        "## split sherpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AInVzuEonrVt"
      },
      "outputs": [],
      "source": [
        "from llmsherpa.readers import LayoutPDFReader\n",
        "\n",
        "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
        "pdf_url = \"/content/Procuradoria Geral - Normas.pdf\"\n",
        "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
        "doc = pdf_reader.read_pdf(pdf_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET5JZzx8rMpu"
      },
      "outputs": [],
      "source": [
        "sherpa_texts = [x.to_context_text() for x in doc.chunks()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JZXsnrHTRoT"
      },
      "source": [
        "## Inicializar banco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Falhjt7ETX2J"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=\"/content/drive/MyDrive/NeuralmindChatBot/banco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ko_PW1BICGl"
      },
      "outputs": [],
      "source": [
        "collection_ada_RecursiveCharacterTextSplitter1000 = chroma_client.create_collection(\n",
        "    name=\"textos_ada_RecursiveCharacterTextSplitter1000\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP2lIhyMTd3-"
      },
      "outputs": [],
      "source": [
        "collection_ada_RecursiveCharacterTextSplitter = chroma_client.create_collection(\n",
        "    name=\"textos_ada_RecursiveCharacterTextSplitter\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "\n",
        "collection_ada_nltk = chroma_client.create_collection(\n",
        "    name=\"textos_ada_nltk\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "\n",
        "collection_ada_sherpa = chroma_client.create_collection(\n",
        "    name=\"textos_ada_sherpa\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Ui89YcT1IF"
      },
      "outputs": [],
      "source": [
        "collection_ada_RecursiveCharacterTextSplitter = chroma_client.get_collection(name=\"textos_ada_RecursiveCharacterTextSplitter\")\n",
        "collection_ada_RecursiveCharacterTextSplitter1000 = chroma_client.get_collection(name=\"textos_ada_RecursiveCharacterTextSplitter1000\")\n",
        "collection_ada_nltk = chroma_client.get_collection(name=\"textos_ada_nltk\")\n",
        "collection_ada_sherpa = chroma_client.get_collection(name=\"textos_ada_sherpa\")\n",
        "\n",
        "collection_e5_large = chroma_client.get_collection(name=\"textos_e5_large_nltk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8jGTUcZVkYG"
      },
      "source": [
        "## Transformar textos em embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spz0fv7wV3ET"
      },
      "source": [
        "### e5-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcJ_xbMZKcD7",
        "outputId": "e2c0dfea-8e1a-4c0b-c5bf-8bfee9338e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=481478f81136a945ec554ae541ecdd626e9ee91c9b01d2170191cc28344ad2c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, safetensors, transformers, sentence_transformers\n",
            "Successfully installed safetensors-0.4.0 sentence_transformers-2.2.2 sentencepiece-0.1.99 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ByNC2GWV1i8"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "multilingual_e5_large = SentenceTransformer('intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVdHeTnCfLkH"
      },
      "outputs": [],
      "source": [
        "e5_texts = [f\"passage: {text}\" for text in nltk_splited_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU92K7nhec0x"
      },
      "outputs": [],
      "source": [
        "embeddings_e5 = multilingual_e5_large.encode(e5_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCB4_c--ezoI"
      },
      "outputs": [],
      "source": [
        "collection_e5_large = chroma_client.create_collection(\n",
        "    name=\"textos_e5_large_nltk\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEd1zFYCfGJQ"
      },
      "outputs": [],
      "source": [
        "collection_e5_large.add(\n",
        "    embeddings = embeddings_e5.tolist(),\n",
        "    documents = e5_texts,\n",
        "    ids=[str(i) for i in range(len(embeddings_e5))]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJknBt6SV6a2"
      },
      "source": [
        "### Ada - Open IA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3HAsvaMV9Ky"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "ada_model = OpenAIEmbeddings(openai_api_key=\"dsad423dsfsd\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stN_FnKn3lvu"
      },
      "outputs": [],
      "source": [
        "embeddings_ada = ada_model.embed_documents(simple_splited_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6Y-Utm0FBbb"
      },
      "outputs": [],
      "source": [
        "embeddings_ada_nltk = ada_model.embed_documents(nltk_splited_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnahKwKTGdn-"
      },
      "outputs": [],
      "source": [
        "embeddings_ada_sherpa = ada_model.embed_documents(sherpa_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ8MEmpq4yER"
      },
      "outputs": [],
      "source": [
        "collection_ada_RecursiveCharacterTextSplitter.add(\n",
        "    embeddings = embeddings_ada,\n",
        "    documents = simple_splited_texts,\n",
        "    ids=[str(i) for i in range(len(simple_splited_texts))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7IMp7cKIP4R"
      },
      "outputs": [],
      "source": [
        "collection_ada_RecursiveCharacterTextSplitter1000.add(\n",
        "    embeddings = embeddings_ada,\n",
        "    documents = simple_splited_texts,\n",
        "    ids=[str(i) for i in range(len(simple_splited_texts))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JixChLKE8aU"
      },
      "outputs": [],
      "source": [
        "collection_ada_nltk.add(\n",
        "    embeddings = embeddings_ada_nltk,\n",
        "    documents = nltk_splited_texts,\n",
        "    ids=[str(i) for i in range(len(nltk_splited_texts))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgA7IxEbG7t0"
      },
      "outputs": [],
      "source": [
        "collection_ada_sherpa.add(\n",
        "    embeddings = embeddings_ada_sherpa,\n",
        "    documents = sherpa_texts,\n",
        "    ids=[str(i) for i in range(len(embeddings_ada_sherpa))]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX9U5i0zWvat"
      },
      "source": [
        "## Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXKtVjnjWyLW"
      },
      "outputs": [],
      "source": [
        "class CustomRetriver:\n",
        "  def __init__(self, collection, embeddingModel, modelName):\n",
        "    self.collection = collection\n",
        "    self.modelName = modelName\n",
        "    self.model = embeddingModel\n",
        "\n",
        "  def embed_query(self, query):\n",
        "    if(self.modelName == \"e5_large\"):\n",
        "      queryText = f\"query: {query}\"\n",
        "      embeddedQuery = self.model.encode([queryText])\n",
        "      return embeddedQuery[0].tolist()\n",
        "    elif(self.modelName == \"open_ia\"):\n",
        "      return self.model.embed_query(query)\n",
        "\n",
        "  def query_topK(self, query, n_results):\n",
        "    embeddedQuery = self.embed_query(query)\n",
        "\n",
        "    results = self.collection.query(\n",
        "      query_embeddings = [embeddedQuery],\n",
        "      n_results = n_results\n",
        "    )\n",
        "\n",
        "    topk = []\n",
        "\n",
        "    for text in results['documents'][0]:\n",
        "      topk.append(text)\n",
        "\n",
        "    return topk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rehLmC0xYDSp"
      },
      "outputs": [],
      "source": [
        "ada_retriever = CustomRetriver(collection_ada_nltk, ada_model, \"open_ia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MV63800f0p-"
      },
      "outputs": [],
      "source": [
        "e5_retriever = CustomRetriver(collection_e5_large, multilingual_e5_large, \"e5_large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMaTzSM4T99A"
      },
      "outputs": [],
      "source": [
        "ada_retriver_sherpa = CustomRetriver(collection_ada_sherpa, ada_model, \"open_ia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RE4lQPBT-H7"
      },
      "outputs": [],
      "source": [
        "ada_retriever_recursive = CustomRetriver(collection_ada_RecursiveCharacterTextSplitter1000, ada_model, \"open_ia\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt6Jla10TEYe"
      },
      "source": [
        "## Avaliação do sistema de retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8LFeBEIEv7s"
      },
      "source": [
        "### Metricas de retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4imOfWLV9x1G"
      },
      "outputs": [],
      "source": [
        "def calculate_map(relevant_texts, retrieved_texts):\n",
        "  total_precision = 0\n",
        "  relevant_count = 0\n",
        "  precision_values = []\n",
        "\n",
        "  for i, text in enumerate(retrieved_texts, start = 1):\n",
        "    if(any([trecho.lower() in text.lower() for trecho in relevant_texts])):\n",
        "      relevant_count += 1\n",
        "      precision_at_i = relevant_count / i\n",
        "      precision_values.append(precision_at_i)\n",
        "\n",
        "  if not precision_values:\n",
        "      return 0\n",
        "\n",
        "  map_score = sum(precision_values) / len(precision_values)\n",
        "  return map_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI2JcEgccJiV"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def calculate_ndcg(relevant_texts, retrieved_texts):\n",
        "    def calculate_dcg(relevances):\n",
        "        dcg = 0\n",
        "        for i, rel in enumerate(relevances, start=1):\n",
        "            dcg += (rel) / math.log2(i + 1)\n",
        "        return dcg\n",
        "\n",
        "    def calculate_idcg(relevances):\n",
        "        sorted_relevances = sorted(relevances, reverse=True)\n",
        "        return calculate_dcg(sorted_relevances)\n",
        "\n",
        "    relevances = [1 if any([trecho.lower() in text for trecho in relevant_texts]) else 0 for text in retrieved_texts]\n",
        "\n",
        "    dcg = calculate_dcg(relevances)\n",
        "\n",
        "    idcg = calculate_idcg(relevances)\n",
        "\n",
        "    if idcg == 0:\n",
        "        ndcg = 0\n",
        "    else:\n",
        "        ndcg = dcg / idcg\n",
        "\n",
        "    return ndcg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5J_GipzjUVv"
      },
      "outputs": [],
      "source": [
        "def calculate_recall_at_k(relevant_texts, retrieved_texts, k):\n",
        "    relevant_count = 0\n",
        "\n",
        "    for i, text in enumerate(retrieved_texts[:k], start = 1):\n",
        "      if(any([trecho.lower() in text.lower() for trecho in relevant_texts[:k]])):\n",
        "        relevant_count += 1\n",
        "\n",
        "    recall_at_k = relevant_count / len(relevant_texts) if len(relevant_texts) > 0 else 0\n",
        "    return recall_at_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "352Zu-WACLzD"
      },
      "outputs": [],
      "source": [
        "def calculate_precision_at_k(relevant_texts, retrieved_texts, k):\n",
        "    relevant_count = 0\n",
        "\n",
        "    for i, text in enumerate(retrieved_texts[:k], start = 1):\n",
        "      if(any([trecho.lower() in text.lower() for trecho in relevant_texts[:k]])):\n",
        "        relevant_count += 1\n",
        "\n",
        "    precision_at_k = relevant_count / k if k > 0 else 0\n",
        "    return precision_at_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFYAmBb_DvFi"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_score(precision, recall):\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9TTo-EaE2lZ"
      },
      "source": [
        "### Função de avaliação do retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEWuAXdJKrUj"
      },
      "outputs": [],
      "source": [
        "def media(resultado, nome):\n",
        "  return f\"{nome}: {sum(resultado[nome]) / len(resultado[nome])}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je8mxC3fl_uL"
      },
      "outputs": [],
      "source": [
        "def salvar_retrieval_results(resultado, nome_exp):\n",
        "  with open(\"/content/drive/MyDrive/NeuralmindChatBot/analises/retrieval.txt\", \"a\") as file:\n",
        "    res = f\"{nome_exp}: \\n\\n\"\n",
        "    res = res + media(resultado, \"maps\") + media(resultado, \"ndcg\") + media(resultado, \"precision_at_three\") + media(resultado, \"recall_at_three\") + media(resultado, \"f1_score\") + \"\\n\\n\"\n",
        "\n",
        "    file.write(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOkhWUp2VFOg"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "\n",
        "def evaluate_retrieval(retrieval_model, dataset_path, model_name):\n",
        "\n",
        "    maps = []\n",
        "    ndcg = []\n",
        "    precision_at_three = []\n",
        "    recall_at_three = []\n",
        "    f1_score = []\n",
        "\n",
        "    with open(dataset_path, 'r') as file:\n",
        "        dataset = csv.reader(file)\n",
        "\n",
        "        for i, row in enumerate(dataset):\n",
        "            question = row[0]\n",
        "            relevant_texts = eval(row[1])\n",
        "            answer = row[2]\n",
        "\n",
        "            time.sleep(21)\n",
        "\n",
        "            retrieved_texts = retrieval_model.query_topK(question, 5)\n",
        "\n",
        "            if(model_name == \"e5_large\"):\n",
        "              retrieved_texts = [text.replace(\"passage: \", \"\", 1) for text in retrieved_texts]\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "            # calculo das metricas MAP e NDCG\n",
        "            maps.append(calculate_map(relevant_texts, retrieved_texts))\n",
        "            ndcg.append(calculate_ndcg(relevant_texts, retrieved_texts))\n",
        "\n",
        "            #calculo das metricas precision, recall and F1 score\n",
        "            precision = calculate_precision_at_k(relevant_texts, retrieved_texts, 3)\n",
        "            recall = calculate_recall_at_k(relevant_texts, retrieved_texts, 3)\n",
        "            precision_at_three.append(precision)\n",
        "            recall_at_three.append(recall)\n",
        "            f1_score.append(calculate_f1_score(precision, recall))\n",
        "\n",
        "    return {\n",
        "        \"maps\": maps,\n",
        "        \"ndcg\": ndcg,\n",
        "        \"precision_at_three\": precision_at_three,\n",
        "        \"recall_at_three\": recall_at_three,\n",
        "        \"f1_score\": f1_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IJC1BLeod3p"
      },
      "source": [
        "### calculando os resultados do retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVJh9IMaGXwK"
      },
      "outputs": [],
      "source": [
        "resultado = evaluate_retrieval(ada_retriever, \"/content/validacaoFinal.csv\", \"open_ia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "088YIo76nVjp"
      },
      "outputs": [],
      "source": [
        "salvar_retrieval_results(resultado, \"embedding ada_002 com Nltk e dataset final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcJws4XzP5qd"
      },
      "outputs": [],
      "source": [
        "resultado[\"ndcg\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayzjHj1ZVBUj"
      },
      "source": [
        "## Avaliação das respostas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FitbQQryplGT"
      },
      "source": [
        "### Metricas para avaliar respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bbjDYhrp8yo",
        "outputId": "7286ce56-7d45-4620-89e6-3526d34ecbc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5GXK0n0rSCJ"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzZN6bhNIFq_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eUrlQbQrWBQ"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "def calculate_precision_recall_f1_tokens(predicted_answer, ground_truth):\n",
        "    predicted_tokens = word_tokenize(predicted_answer.lower())\n",
        "    ground_truth_tokens = word_tokenize(ground_truth.lower())\n",
        "\n",
        "    # True Positives: Number of common tokens between predicted and ground truth\n",
        "    TP = len(set(predicted_tokens) & set(ground_truth_tokens))\n",
        "\n",
        "    # False Positives: Number of tokens in predicted but not in ground truth\n",
        "    FP = len(set(predicted_tokens) - set(ground_truth_tokens))\n",
        "\n",
        "    # False Negatives: Number of tokens in ground truth but not in predicted\n",
        "    FN = len(set(ground_truth_tokens) - set(predicted_tokens))\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    return precision, recall, calculate_f1_score(precision, recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_QaEblYIom6"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "model = CrossEncoder('cross-encoder/stsb-roberta-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXmPYCyhL-kI"
      },
      "outputs": [],
      "source": [
        "def similarity(predicted, expected):\n",
        "  res = model.predict([predicted, expected])\n",
        "  return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6VIyFDdpvF5"
      },
      "source": [
        "### Função de avaliação de respostas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3qUvftBYm1y"
      },
      "source": [
        "#### Instanciando o LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZsgKK6J4dspm"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = OpenAI(openai_api_key=\"vSKT3TrPyqRkjV6uR6wbo9S9\")\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=\"hKQGvSJ1TrPyqRkjV6uR6wbo9S9\", max_tokens=250, model = \"gpt-3.5-turbo\", temperature=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "CwD__cpUG_RG"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"Considering these texts as context: {context}.\n",
        "    Give me a brilliant answer to the following question: {question}\n",
        "\n",
        "    Make sure to answer using Portuguese language\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "f45ux77_qvob"
      },
      "outputs": [],
      "source": [
        "chain = prompt | chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAIX5IOKMvtu"
      },
      "source": [
        "#### Função de avaliação das respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "evQ_IpPJraTa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "\n",
        "def evaluate_question_answering(chain, retriever, dataset_path, model_name):\n",
        "\n",
        "  predictions = []\n",
        "  references = []\n",
        "\n",
        "  precision_list = []\n",
        "  recall_list = []\n",
        "  f1_score_list = []\n",
        "  cross_encoder_similarity = []\n",
        "\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "        dataset = csv.reader(file)\n",
        "\n",
        "        for i, row in enumerate(dataset):\n",
        "            question = row[0]\n",
        "            human_answer = row[2]\n",
        "\n",
        "            retrieved_texts = retriever.query_topK(question, 10)\n",
        "\n",
        "            if(model_name == \"e5_large\"):\n",
        "              retrieved_texts = [text.replace(\"passage: \", \"\", 1) for text in retrieved_texts]\n",
        "\n",
        "            context = \"\\n\".join(retrieved_texts)\n",
        "\n",
        "            predicted_answer = chain.invoke({\"context\": context, \"question\": question})\n",
        "\n",
        "            time.sleep(21)\n",
        "\n",
        "            predicted_answer = predicted_answer.content\n",
        "\n",
        "            precision, recall, f1_score = calculate_precision_recall_f1_tokens(predicted_answer, human_answer)\n",
        "\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_score_list.append(f1_score)\n",
        "\n",
        "            predictions.append(predicted_answer)\n",
        "            references.append(human_answer)\n",
        "\n",
        "            cross_encoder_similarity.append(similarity(predicted_answer, human_answer))\n",
        "\n",
        "  bleu_res = bleu.compute(predictions=predictions, references=references)\n",
        "\n",
        "  return {\n",
        "      \"bleu\": bleu_res,\n",
        "      \"precision_list\": precision_list,\n",
        "      \"recall_list\": recall_list,\n",
        "      \"f1_score_list\": f1_score_list,\n",
        "      \"cross_encoder_similarity\": cross_encoder_similarity,\n",
        "      \"answers\":  predictions\n",
        "  }\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlqmAcEmp1-A"
      },
      "source": [
        "### calculando resultados das respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_aC2t4Wp92Q"
      },
      "outputs": [],
      "source": [
        "qa_evaluation = evaluate_question_answering(chain, ada_retriever, \"/content/validacaoFinal.csv\", \"open_ia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "HdgLW9i7TMXB"
      },
      "outputs": [],
      "source": [
        "def salvar_qa_results(resultado, nome_exp):\n",
        "  with open(\"/content/drive/MyDrive/NeuralmindChatBot/analises/qa_evaluate.txt\", \"a\") as file:\n",
        "    res = f\"{nome_exp}: \\n\\n\"\n",
        "\n",
        "    bleu_str = f'bleu: {resultado[\"bleu\"]}\\n'\n",
        "\n",
        "    res = res + bleu_str + media(resultado, \"precision_list\") + media(resultado, \"recall_list\") + media(resultado, \"f1_score_list\") + media(resultado, \"cross_encoder_similarity\") + \"\\n\\n\"\n",
        "\n",
        "    file.write(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "MnwCL83Rp2oz"
      },
      "outputs": [],
      "source": [
        "salvar_qa_results(qa_evaluation, \"chat-gpt-3.5-turbo | ada_002 | nltk spliterr | dataset final | max_tokens = 100 | Discursivamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "zbR79pzUxjka"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/NeuralmindChatBot/analises/respostasNovas.txt\", \"w\") as file:\n",
        "    for res in qa_evaluation[\"answers\"]:\n",
        "      file.writelines(res + \"\\n --------------------------------------- \\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n1cmjI71jSJ"
      },
      "outputs": [],
      "source": [
        "qa_evaluation[\"cross_encoder_similarity\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
